{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847e1412-b49a-4a2f-b58a-f03b1384f6a6",
   "metadata": {},
   "source": [
    "# Missing Data Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84bfb0-60e9-4a41-8bb9-11d9a6ef0c3c",
   "metadata": {},
   "source": [
    "##### This Python code performs data preprocessing and classification operations on the missing dataset. Firstly, the data is read from the CSV file using the pandas library and the columns with missing data are filled with SimpleImputer. After the missing data filling process, the data is converted into categorical data into numerical data with LabelEncoder and OneHotEncoder. Then, these data are transferred to pandas DataFrames and merged. The data is split into training and test sets (train_test_split), then the features are scaled using StandardScaler. A Logistic Regression model is created (LogisticRegression), trained with the training set and predicted with the test set. Finally, the predicted and actual values are printed on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3112920c-944e-4513-b9dd-6ceddee0bf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country  Size  Weight   Age sex\n",
      "0       tr   130      30  10.0   m\n",
      "1       tr   125      36  11.0   m\n",
      "2       tr   135      34  10.0   w\n",
      "3       tr   133      30   9.0   m\n",
      "4       tr   129      38  12.0   m\n",
      "5       tr   180      90  30.0   m\n",
      "6       tr   190      80  25.0   m\n",
      "7       tr   175      90  35.0   m\n",
      "8       tr   177      60  22.0   w\n",
      "9       us   185     105  33.0   m\n",
      "10      us   165      55  27.0   w\n",
      "11      us   155      50  44.0   w\n",
      "12      us   160      58   NaN   w\n",
      "13      us   162      59  41.0   w\n",
      "14      us   167      62  55.0   w\n",
      "15      fr   174      70  47.0   m\n",
      "16      fr   193      90   NaN   m\n",
      "17      fr   187      80  27.0   m\n",
      "18      fr   183      88  28.0   m\n",
      "19      fr   159      40  29.0   w\n",
      "20      fr   164      66  32.0   w\n",
      "21      fr   166      56  42.0   w\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Arif Furkan\\\\OneDrive\\\\Belgeler\\\\Python_kullanirken\\\\eksikveriler.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad86c21-99c3-4bf0-83d8-4c192824ae3d",
   "metadata": {},
   "source": [
    "## Filling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e024ff2-8696-4bb0-9fdc-b638db0a556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130.  30.  10.]\n",
      " [125.  36.  11.]\n",
      " [135.  34.  10.]\n",
      " [133.  30.   9.]\n",
      " [129.  38.  12.]\n",
      " [180.  90.  30.]\n",
      " [190.  80.  25.]\n",
      " [175.  90.  35.]\n",
      " [177.  60.  22.]\n",
      " [185. 105.  33.]\n",
      " [165.  55.  27.]\n",
      " [155.  50.  44.]\n",
      " [160.  58.  nan]\n",
      " [162.  59.  41.]\n",
      " [167.  62.  55.]\n",
      " [174.  70.  47.]\n",
      " [193.  90.  nan]\n",
      " [187.  80.  27.]\n",
      " [183.  88.  28.]\n",
      " [159.  40.  29.]\n",
      " [164.  66.  32.]\n",
      " [166.  56.  42.]]\n",
      "[[130.    30.    10.  ]\n",
      " [125.    36.    11.  ]\n",
      " [135.    34.    10.  ]\n",
      " [133.    30.     9.  ]\n",
      " [129.    38.    12.  ]\n",
      " [180.    90.    30.  ]\n",
      " [190.    80.    25.  ]\n",
      " [175.    90.    35.  ]\n",
      " [177.    60.    22.  ]\n",
      " [185.   105.    33.  ]\n",
      " [165.    55.    27.  ]\n",
      " [155.    50.    44.  ]\n",
      " [160.    58.    28.45]\n",
      " [162.    59.    41.  ]\n",
      " [167.    62.    55.  ]\n",
      " [174.    70.    47.  ]\n",
      " [193.    90.    28.45]\n",
      " [187.    80.    27.  ]\n",
      " [183.    88.    28.  ]\n",
      " [159.    40.    29.  ]\n",
      " [164.    66.    32.  ]\n",
      " [166.    56.    42.  ]]\n",
      "[['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Age = data.iloc[:, 1:4].values  \n",
    "print(Age)\n",
    "imputer = imputer.fit(Age[:, 1:4]) \n",
    "Age[:, 1:4] = imputer.transform(Age[:, 1:4])\n",
    "print(Age)\n",
    "Country = data.iloc[:, 0:1].values\n",
    "print(Country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5de4a-f910-4700-a905-fbf65d318161",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "605fa5f3-a2c8-46e3-a0d3-131a0b1e101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder() \n",
    "Country[:, 0] = le.fit_transform(data.iloc[:, 0])\n",
    "print(Country)\n",
    "ohe = preprocessing.OneHotEncoder()  \n",
    "Country = ohe.fit_transform(Country).toarray() \n",
    "print(Country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183c548-ae53-4382-a066-d8142ae22ae0",
   "metadata": {},
   "source": [
    "## Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef82766-25e2-4f7b-b658-74a446e4ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "     fr   tr   us\n",
      "0   0.0  1.0  0.0\n",
      "1   0.0  1.0  0.0\n",
      "2   0.0  1.0  0.0\n",
      "3   0.0  1.0  0.0\n",
      "4   0.0  1.0  0.0\n",
      "5   0.0  1.0  0.0\n",
      "6   0.0  1.0  0.0\n",
      "7   0.0  1.0  0.0\n",
      "8   0.0  1.0  0.0\n",
      "9   0.0  0.0  1.0\n",
      "10  0.0  0.0  1.0\n",
      "11  0.0  0.0  1.0\n",
      "12  0.0  0.0  1.0\n",
      "13  0.0  0.0  1.0\n",
      "14  0.0  0.0  1.0\n",
      "15  1.0  0.0  0.0\n",
      "16  1.0  0.0  0.0\n",
      "17  1.0  0.0  0.0\n",
      "18  1.0  0.0  0.0\n",
      "19  1.0  0.0  0.0\n",
      "20  1.0  0.0  0.0\n",
      "21  1.0  0.0  0.0\n",
      "     Size  Weight    Age\n",
      "0   130.0    30.0  10.00\n",
      "1   125.0    36.0  11.00\n",
      "2   135.0    34.0  10.00\n",
      "3   133.0    30.0   9.00\n",
      "4   129.0    38.0  12.00\n",
      "5   180.0    90.0  30.00\n",
      "6   190.0    80.0  25.00\n",
      "7   175.0    90.0  35.00\n",
      "8   177.0    60.0  22.00\n",
      "9   185.0   105.0  33.00\n",
      "10  165.0    55.0  27.00\n",
      "11  155.0    50.0  44.00\n",
      "12  160.0    58.0  28.45\n",
      "13  162.0    59.0  41.00\n",
      "14  167.0    62.0  55.00\n",
      "15  174.0    70.0  47.00\n",
      "16  193.0    90.0  28.45\n",
      "17  187.0    80.0  27.00\n",
      "18  183.0    88.0  28.00\n",
      "19  159.0    40.0  29.00\n",
      "20  164.0    66.0  32.00\n",
      "21  166.0    56.0  42.00\n",
      "['m' 'm' 'w' 'm' 'm' 'm' 'm' 'm' 'w' 'm' 'w' 'w' 'w' 'w' 'w' 'm' 'm' 'm'\n",
      " 'm' 'w' 'w' 'w']\n",
      "   sex\n",
      "0    m\n",
      "1    m\n",
      "2    w\n",
      "3    m\n",
      "4    m\n",
      "5    m\n",
      "6    m\n",
      "7    m\n",
      "8    w\n",
      "9    m\n",
      "10   w\n",
      "11   w\n",
      "12   w\n",
      "13   w\n",
      "14   w\n",
      "15   m\n",
      "16   m\n",
      "17   m\n",
      "18   m\n",
      "19   w\n",
      "20   w\n",
      "21   w\n"
     ]
    }
   ],
   "source": [
    "print(list(range(22)))\n",
    "result = pd.DataFrame(data=Country, index=range(22), columns=['fr', 'tr', 'us'])\n",
    "print(result)\n",
    "result2 = pd.DataFrame(data=Age, index=range(22), columns=['Size', 'Weight', 'Age'])\n",
    "print(result2)\n",
    "sex = data.iloc[:, -1].values\n",
    "print(sex)\n",
    "result3 = pd.DataFrame(data=sex, index=range(22), columns=['sex'])\n",
    "print(result3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdaf563-0587-4aeb-82e1-87c6f6f8fda2",
   "metadata": {},
   "source": [
    "## Merging All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3985043-c6e0-47f0-9b7c-4429b5344ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr   us   Size  Weight    Age\n",
      "0   0.0  1.0  0.0  130.0    30.0  10.00\n",
      "1   0.0  1.0  0.0  125.0    36.0  11.00\n",
      "2   0.0  1.0  0.0  135.0    34.0  10.00\n",
      "3   0.0  1.0  0.0  133.0    30.0   9.00\n",
      "4   0.0  1.0  0.0  129.0    38.0  12.00\n",
      "5   0.0  1.0  0.0  180.0    90.0  30.00\n",
      "6   0.0  1.0  0.0  190.0    80.0  25.00\n",
      "7   0.0  1.0  0.0  175.0    90.0  35.00\n",
      "8   0.0  1.0  0.0  177.0    60.0  22.00\n",
      "9   0.0  0.0  1.0  185.0   105.0  33.00\n",
      "10  0.0  0.0  1.0  165.0    55.0  27.00\n",
      "11  0.0  0.0  1.0  155.0    50.0  44.00\n",
      "12  0.0  0.0  1.0  160.0    58.0  28.45\n",
      "13  0.0  0.0  1.0  162.0    59.0  41.00\n",
      "14  0.0  0.0  1.0  167.0    62.0  55.00\n",
      "15  1.0  0.0  0.0  174.0    70.0  47.00\n",
      "16  1.0  0.0  0.0  193.0    90.0  28.45\n",
      "17  1.0  0.0  0.0  187.0    80.0  27.00\n",
      "18  1.0  0.0  0.0  183.0    88.0  28.00\n",
      "19  1.0  0.0  0.0  159.0    40.0  29.00\n",
      "20  1.0  0.0  0.0  164.0    66.0  32.00\n",
      "21  1.0  0.0  0.0  166.0    56.0  42.00\n",
      "     fr   tr   us   Size  Weight    Age sex\n",
      "0   0.0  1.0  0.0  130.0    30.0  10.00   m\n",
      "1   0.0  1.0  0.0  125.0    36.0  11.00   m\n",
      "2   0.0  1.0  0.0  135.0    34.0  10.00   w\n",
      "3   0.0  1.0  0.0  133.0    30.0   9.00   m\n",
      "4   0.0  1.0  0.0  129.0    38.0  12.00   m\n",
      "5   0.0  1.0  0.0  180.0    90.0  30.00   m\n",
      "6   0.0  1.0  0.0  190.0    80.0  25.00   m\n",
      "7   0.0  1.0  0.0  175.0    90.0  35.00   m\n",
      "8   0.0  1.0  0.0  177.0    60.0  22.00   w\n",
      "9   0.0  0.0  1.0  185.0   105.0  33.00   m\n",
      "10  0.0  0.0  1.0  165.0    55.0  27.00   w\n",
      "11  0.0  0.0  1.0  155.0    50.0  44.00   w\n",
      "12  0.0  0.0  1.0  160.0    58.0  28.45   w\n",
      "13  0.0  0.0  1.0  162.0    59.0  41.00   w\n",
      "14  0.0  0.0  1.0  167.0    62.0  55.00   w\n",
      "15  1.0  0.0  0.0  174.0    70.0  47.00   m\n",
      "16  1.0  0.0  0.0  193.0    90.0  28.45   m\n",
      "17  1.0  0.0  0.0  187.0    80.0  27.00   m\n",
      "18  1.0  0.0  0.0  183.0    88.0  28.00   m\n",
      "19  1.0  0.0  0.0  159.0    40.0  29.00   w\n",
      "20  1.0  0.0  0.0  164.0    66.0  32.00   w\n",
      "21  1.0  0.0  0.0  166.0    56.0  42.00   w\n"
     ]
    }
   ],
   "source": [
    "r = pd.concat([result, result2], axis=1) \n",
    "print(r)\n",
    "r2 = pd.concat([r, result3], axis=1)\n",
    "print(r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dced825-e576-491c-9df2-edfd93fa03cb",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d544a4bf-0e9f-4f6b-af4d-6ce8c28decd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(r, result3, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87199881-233e-41f0-844c-6a296ef3426b",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4d1d4d6-837e-4716-8ad6-600f8acc1724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'w' 'm' 'w' 'm' 'm' 'w' 'm']\n",
      "['w' 'w' 'w' 'w' 'm' 'w' 'w' 'w']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler() \n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.transform(x_test) \n",
    "y_train = np.ravel(y_train.to_numpy())\n",
    "y_test = np.ravel(y_test.to_numpy())\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression(random_state=0) \n",
    "logr.fit(X_train, y_train)\n",
    "y_pred = logr.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
